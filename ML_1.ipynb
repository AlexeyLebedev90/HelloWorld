{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "con = sqlite3.connect(\":memory:\")\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "link = 'https://raw.githubusercontent.com/eric-bunch/boston_housing/master/boston.csv'\n",
    "data = pd.read_csv(link)\n",
    "data.rename(columns = {'MDEV':'MEDV'}, inplace=True)\n",
    "data.to_sql(\"boston\", con, index=False, if_exists=\"replace\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function load_boston is deprecated; `load_boston` is deprecated in 1.0 and will be removed in 1.2.\n",
      "\n",
      "    The Boston housing prices dataset has an ethical problem. You can refer to\n",
      "    the documentation of this function for further details.\n",
      "\n",
      "    The scikit-learn maintainers therefore strongly discourage the use of this\n",
      "    dataset unless the purpose of the code is to study and educate about\n",
      "    ethical issues in data science and machine learning.\n",
      "\n",
      "    In this special case, you can fetch the dataset from the original\n",
      "    source::\n",
      "\n",
      "        import pandas as pd\n",
      "        import numpy as np\n",
      "\n",
      "\n",
      "        data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
      "        raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)\n",
      "        data = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
      "        target = raw_df.values[1::2, 2]\n",
      "\n",
      "    Alternative datasets include the California housing dataset (i.e.\n",
      "    :func:`~sklearn.datasets.fetch_california_housing`) and the Ames housing\n",
      "    dataset. You can load the datasets as follows::\n",
      "\n",
      "        from sklearn.datasets import fetch_california_housing\n",
      "        housing = fetch_california_housing()\n",
      "\n",
      "    for the California housing dataset and::\n",
      "\n",
      "        from sklearn.datasets import fetch_openml\n",
      "        housing = fetch_openml(name=\"house_prices\", as_frame=True)\n",
      "\n",
      "    for the Ames housing dataset.\n",
      "    \n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "dataset = load_boston()\n",
    "X = pd.DataFrame(dataset.data)\n",
    "X.columns = dataset.feature_names\n",
    "y = dataset.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Разделите выборку на обучающую и тестовую в отношении 80%/20%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Обучите стандартную регрессию, а также Ridge и  Lasso и параметрами по умолчанию и выведите их R2 на тестовой выборке"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6687594935356332"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "LR = LinearRegression().fit(X_train, y_train)\n",
    "PR = LR.predict(X_test)\n",
    "R2 = r2_score(y_test, PR)\n",
    "R2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6662221670168521"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R = Ridge().fit(X_train, y_train)\n",
    "PR = R.predict(X_test)\n",
    "R2 = r2_score(y_test, PR)\n",
    "R2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6671453631686304"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L = Lasso().fit(X_train, y_train) \n",
    "PR = L.predict(X_test)\n",
    "R2 = r2_score(y_test, PR)\n",
    "R2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Для Ridge и Lasso подберите коэффициент регуляризации(используйте GridSearchCV, RidgeCV, LassoCV) в пределах от $10^{-5}$ до $10^5$ (по степеням 10). Посчитайте R2 на тестовой выборке по лучшим моделям и сравните с предыдущими результатами. Напишите как изменился результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeCV, LassoCV\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "data =[]\n",
    "for i in range(-5,5):\n",
    "    data.append(10**i)\n",
    "GS = GridSearchCV(R, {'alpha':data}).fit(X_train,y_train)\n",
    "LS = GridSearchCV(L, {'alpha':data}).fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpha': 1e-05}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GS.best_params_\n",
    "LS.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.668751010992999"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RC = RidgeCV(data).fit(X_train, y_train)\n",
    "r2_score(y_test, RC.predict(X_test))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6706431115795963"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LC = LassoCV().fit(X_train, y_train)\n",
    "r2_score(y_test, LC.predict(X_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты полученные с использованием LassoCV показали лучшее качество\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Подберите коэффициент регуляризации для Ridge и Lasso на масштабированных данных, посчитайте R2 и сравните с предыдущими результатами. Напишите как изменился результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6659677905050388\n",
      "0.6683883969336302\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "RC = Pipeline ([('GS', StandardScaler()), \n",
    "                    ('model', RidgeCV())])\n",
    "LC = Pipeline([('GS', StandardScaler()), \n",
    "                     ('model', LassoCV())])\n",
    "RC.fit(X_train, y_train)\n",
    "LC.fit(X_train, y_train)\n",
    "print(r2_score(y_test, RC.predict(X_test)))\n",
    "print(r2_score(y_test, LC.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат улучшился"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Добавьте попарные произведения признаков и их квадраты (используйте PolynomialFeatures) на масштабированных признаках, посчитайте R2 и сравните с предыдущими результатами. Напишите как изменился результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>95</th>\n",
       "      <th>96</th>\n",
       "      <th>97</th>\n",
       "      <th>98</th>\n",
       "      <th>99</th>\n",
       "      <th>100</th>\n",
       "      <th>101</th>\n",
       "      <th>102</th>\n",
       "      <th>103</th>\n",
       "      <th>104</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00632</td>\n",
       "      <td>18.0</td>\n",
       "      <td>2.31</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.538</td>\n",
       "      <td>6.575</td>\n",
       "      <td>65.2</td>\n",
       "      <td>4.0900</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>87616.0</td>\n",
       "      <td>4528.8</td>\n",
       "      <td>117482.40</td>\n",
       "      <td>1474.08</td>\n",
       "      <td>234.09</td>\n",
       "      <td>6072.570</td>\n",
       "      <td>76.194</td>\n",
       "      <td>157529.6100</td>\n",
       "      <td>1976.5620</td>\n",
       "      <td>24.8004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.02731</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>6.421</td>\n",
       "      <td>78.9</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>58564.0</td>\n",
       "      <td>4307.6</td>\n",
       "      <td>96049.80</td>\n",
       "      <td>2211.88</td>\n",
       "      <td>316.84</td>\n",
       "      <td>7064.820</td>\n",
       "      <td>162.692</td>\n",
       "      <td>157529.6100</td>\n",
       "      <td>3627.6660</td>\n",
       "      <td>83.5396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.02729</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.07</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.469</td>\n",
       "      <td>7.185</td>\n",
       "      <td>61.1</td>\n",
       "      <td>4.9671</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>58564.0</td>\n",
       "      <td>4307.6</td>\n",
       "      <td>95064.86</td>\n",
       "      <td>975.26</td>\n",
       "      <td>316.84</td>\n",
       "      <td>6992.374</td>\n",
       "      <td>71.734</td>\n",
       "      <td>154315.4089</td>\n",
       "      <td>1583.1049</td>\n",
       "      <td>16.2409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.03237</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>6.998</td>\n",
       "      <td>45.8</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>49284.0</td>\n",
       "      <td>4151.4</td>\n",
       "      <td>87607.86</td>\n",
       "      <td>652.68</td>\n",
       "      <td>349.69</td>\n",
       "      <td>7379.581</td>\n",
       "      <td>54.978</td>\n",
       "      <td>155732.8369</td>\n",
       "      <td>1160.2122</td>\n",
       "      <td>8.6436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.06905</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.18</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.458</td>\n",
       "      <td>7.147</td>\n",
       "      <td>54.2</td>\n",
       "      <td>6.0622</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>49284.0</td>\n",
       "      <td>4151.4</td>\n",
       "      <td>88111.80</td>\n",
       "      <td>1183.26</td>\n",
       "      <td>349.69</td>\n",
       "      <td>7422.030</td>\n",
       "      <td>99.671</td>\n",
       "      <td>157529.6100</td>\n",
       "      <td>2115.4770</td>\n",
       "      <td>28.4089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>501</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.06263</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.593</td>\n",
       "      <td>69.1</td>\n",
       "      <td>2.4786</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>74529.0</td>\n",
       "      <td>5733.0</td>\n",
       "      <td>107013.27</td>\n",
       "      <td>2639.91</td>\n",
       "      <td>441.00</td>\n",
       "      <td>8231.790</td>\n",
       "      <td>203.070</td>\n",
       "      <td>153656.1601</td>\n",
       "      <td>3790.5433</td>\n",
       "      <td>93.5089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>502</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.04527</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.120</td>\n",
       "      <td>76.7</td>\n",
       "      <td>2.2875</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>74529.0</td>\n",
       "      <td>5733.0</td>\n",
       "      <td>108353.70</td>\n",
       "      <td>2478.84</td>\n",
       "      <td>441.00</td>\n",
       "      <td>8334.900</td>\n",
       "      <td>190.680</td>\n",
       "      <td>157529.6100</td>\n",
       "      <td>3603.8520</td>\n",
       "      <td>82.4464</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>503</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.06076</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>2.1675</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>74529.0</td>\n",
       "      <td>5733.0</td>\n",
       "      <td>108353.70</td>\n",
       "      <td>1539.72</td>\n",
       "      <td>441.00</td>\n",
       "      <td>8334.900</td>\n",
       "      <td>118.440</td>\n",
       "      <td>157529.6100</td>\n",
       "      <td>2238.5160</td>\n",
       "      <td>31.8096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>504</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10959</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.794</td>\n",
       "      <td>89.3</td>\n",
       "      <td>2.3889</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>74529.0</td>\n",
       "      <td>5733.0</td>\n",
       "      <td>107411.85</td>\n",
       "      <td>1769.04</td>\n",
       "      <td>441.00</td>\n",
       "      <td>8262.450</td>\n",
       "      <td>136.080</td>\n",
       "      <td>154802.9025</td>\n",
       "      <td>2549.5560</td>\n",
       "      <td>41.9904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>505</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.04741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.93</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.573</td>\n",
       "      <td>6.030</td>\n",
       "      <td>80.8</td>\n",
       "      <td>2.5050</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>74529.0</td>\n",
       "      <td>5733.0</td>\n",
       "      <td>108353.70</td>\n",
       "      <td>2151.24</td>\n",
       "      <td>441.00</td>\n",
       "      <td>8334.900</td>\n",
       "      <td>165.480</td>\n",
       "      <td>157529.6100</td>\n",
       "      <td>3127.5720</td>\n",
       "      <td>62.0944</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>506 rows × 105 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0        1     2      3    4      5      6     7       8    9    ...  \\\n",
       "0    1.0  0.00632  18.0   2.31  0.0  0.538  6.575  65.2  4.0900  1.0  ...   \n",
       "1    1.0  0.02731   0.0   7.07  0.0  0.469  6.421  78.9  4.9671  2.0  ...   \n",
       "2    1.0  0.02729   0.0   7.07  0.0  0.469  7.185  61.1  4.9671  2.0  ...   \n",
       "3    1.0  0.03237   0.0   2.18  0.0  0.458  6.998  45.8  6.0622  3.0  ...   \n",
       "4    1.0  0.06905   0.0   2.18  0.0  0.458  7.147  54.2  6.0622  3.0  ...   \n",
       "..   ...      ...   ...    ...  ...    ...    ...   ...     ...  ...  ...   \n",
       "501  1.0  0.06263   0.0  11.93  0.0  0.573  6.593  69.1  2.4786  1.0  ...   \n",
       "502  1.0  0.04527   0.0  11.93  0.0  0.573  6.120  76.7  2.2875  1.0  ...   \n",
       "503  1.0  0.06076   0.0  11.93  0.0  0.573  6.976  91.0  2.1675  1.0  ...   \n",
       "504  1.0  0.10959   0.0  11.93  0.0  0.573  6.794  89.3  2.3889  1.0  ...   \n",
       "505  1.0  0.04741   0.0  11.93  0.0  0.573  6.030  80.8  2.5050  1.0  ...   \n",
       "\n",
       "         95      96         97       98      99        100      101  \\\n",
       "0    87616.0  4528.8  117482.40  1474.08  234.09  6072.570   76.194   \n",
       "1    58564.0  4307.6   96049.80  2211.88  316.84  7064.820  162.692   \n",
       "2    58564.0  4307.6   95064.86   975.26  316.84  6992.374   71.734   \n",
       "3    49284.0  4151.4   87607.86   652.68  349.69  7379.581   54.978   \n",
       "4    49284.0  4151.4   88111.80  1183.26  349.69  7422.030   99.671   \n",
       "..       ...     ...        ...      ...     ...       ...      ...   \n",
       "501  74529.0  5733.0  107013.27  2639.91  441.00  8231.790  203.070   \n",
       "502  74529.0  5733.0  108353.70  2478.84  441.00  8334.900  190.680   \n",
       "503  74529.0  5733.0  108353.70  1539.72  441.00  8334.900  118.440   \n",
       "504  74529.0  5733.0  107411.85  1769.04  441.00  8262.450  136.080   \n",
       "505  74529.0  5733.0  108353.70  2151.24  441.00  8334.900  165.480   \n",
       "\n",
       "             102        103      104  \n",
       "0    157529.6100  1976.5620  24.8004  \n",
       "1    157529.6100  3627.6660  83.5396  \n",
       "2    154315.4089  1583.1049  16.2409  \n",
       "3    155732.8369  1160.2122   8.6436  \n",
       "4    157529.6100  2115.4770  28.4089  \n",
       "..           ...        ...      ...  \n",
       "501  153656.1601  3790.5433  93.5089  \n",
       "502  157529.6100  3603.8520  82.4464  \n",
       "503  157529.6100  2238.5160  31.8096  \n",
       "504  154802.9025  2549.5560  41.9904  \n",
       "505  157529.6100  3127.5720  62.0944  \n",
       "\n",
       "[506 rows x 105 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "poly = PolynomialFeatures(2)\n",
    "df = pd.DataFrame(poly.fit_transform(X))\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6167961299626735\n",
      "0.5861967202158876\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:647: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations, check the scale of the features or consider increasing regularisation. Duality gap: 2.967e+03, tolerance: 4.262e+00\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df, y, test_size =2, random_state=42)\n",
    "R = Ridge().fit(X_train, y_train)\n",
    "L = Lasso().fit(X_train, y_train)\n",
    "print(r2_score(y_test, R.predict(X_test)))\n",
    "print(r2_score(y_test, L.predict(X_test)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Видно увеличение качества обучения"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "http://archive.ics.uci.edu/ml/datasets/Adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "link = 'https://raw.githubusercontent.com/jbrownlee/Datasets/master/adult-all.csv'\n",
    "data = pd.read_csv(link, header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>39</td>\n",
       "      <td>State-gov</td>\n",
       "      <td>77516</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Never-married</td>\n",
       "      <td>Adm-clerical</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>2174</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>50</td>\n",
       "      <td>Self-emp-not-inc</td>\n",
       "      <td>83311</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Exec-managerial</td>\n",
       "      <td>Husband</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38</td>\n",
       "      <td>Private</td>\n",
       "      <td>215646</td>\n",
       "      <td>HS-grad</td>\n",
       "      <td>9</td>\n",
       "      <td>Divorced</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Not-in-family</td>\n",
       "      <td>White</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>53</td>\n",
       "      <td>Private</td>\n",
       "      <td>234721</td>\n",
       "      <td>11th</td>\n",
       "      <td>7</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Handlers-cleaners</td>\n",
       "      <td>Husband</td>\n",
       "      <td>Black</td>\n",
       "      <td>Male</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>United-States</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>28</td>\n",
       "      <td>Private</td>\n",
       "      <td>338409</td>\n",
       "      <td>Bachelors</td>\n",
       "      <td>13</td>\n",
       "      <td>Married-civ-spouse</td>\n",
       "      <td>Prof-specialty</td>\n",
       "      <td>Wife</td>\n",
       "      <td>Black</td>\n",
       "      <td>Female</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>Cuba</td>\n",
       "      <td>&lt;=50K</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                 1       2          3   4                   5   \\\n",
       "0  39         State-gov   77516  Bachelors  13       Never-married   \n",
       "1  50  Self-emp-not-inc   83311  Bachelors  13  Married-civ-spouse   \n",
       "2  38           Private  215646    HS-grad   9            Divorced   \n",
       "3  53           Private  234721       11th   7  Married-civ-spouse   \n",
       "4  28           Private  338409  Bachelors  13  Married-civ-spouse   \n",
       "\n",
       "                  6              7      8       9     10  11  12  \\\n",
       "0       Adm-clerical  Not-in-family  White    Male  2174   0  40   \n",
       "1    Exec-managerial        Husband  White    Male     0   0  13   \n",
       "2  Handlers-cleaners  Not-in-family  White    Male     0   0  40   \n",
       "3  Handlers-cleaners        Husband  Black    Male     0   0  40   \n",
       "4     Prof-specialty           Wife  Black  Female     0   0  40   \n",
       "\n",
       "              13     14  \n",
       "0  United-States  <=50K  \n",
       "1  United-States  <=50K  \n",
       "2  United-States  <=50K  \n",
       "3  United-States  <=50K  \n",
       "4           Cuba  <=50K  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. Разделите выборку на признаки и целевую переменную(колонка со зачениями {<=50K,>50K}). Замените целевую переменную на числовые значения."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>14</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   14\n",
       "0   0\n",
       "1   0\n",
       "2   0\n",
       "3   0\n",
       "4   0\n",
       "5   0\n",
       "6   0\n",
       "7   1\n",
       "8   1\n",
       "9   1"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = data.columns\n",
    "X = data[df[:-1]]\n",
    "y = data[df[-1:]].applymap(lambda x: 0 if str(x) == \"<=50K\" else 1)\n",
    "y.head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "9. Выясните, присутствуют ли в данных пропуски. Заполните их самыми частыми значениями (испольуйте SimpleImputer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.impute import SimpleImputer\n",
    "most_frequent = SimpleImputer(missing_values=np.nan, strategy='most_frequent')\n",
    "df = pd.DataFrame(most_frequent.fit_transform(X))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "10. Выберите колонки с числовыми и категориальными переменными."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Int64Index([0, 2, 4, 10, 11, 12], dtype='int64') Int64Index([1, 3, 5, 6, 7, 8, 9, 13], dtype='int64')\n"
     ]
    }
   ],
   "source": [
    "num = X.select_dtypes(include=['int64', 'float64']).columns\n",
    "cat = X.select_dtypes(include=['object']).columns\n",
    "print(num, cat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "11.Создайте пайплайн по обработке колонок(используйте OneHotEncoder,MinMaxScaler).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder, MinMaxScaler\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "num_trans = Pipeline(steps=[\n",
    "    ('MS', MinMaxScaler())])\n",
    "cat_trans = Pipeline(steps=[\n",
    "    ('OE', OneHotEncoder())])\n",
    "pre = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_trans, num),\n",
    "        ('cat', cat_trans, cat)\n",
    "        ])\n",
    "t_pre = pre.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "12. Посчитайте метрики accuracy и f1_score на предсказании только самого частого класса в целевой переменной."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0 1.0\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score as acc, f1_score as f1\n",
    "from sklearn.linear_model import LinearRegression as LR\n",
    "import time\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)\n",
    "print(acc(y, y_pred=y),\n",
    "f1(y, y_pred=y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "13. Посчитайте cross_val_score по алгоритмам LogisticRegression, SVC, LinearSVC по метрикам accuracy и f1_score.\n",
    "Напишите удалось ли превзойти предыдущий результат."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8567772317772318 0.6661894535910284\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score as cr\n",
    "from sklearn.linear_model import LogisticRegression as LG\n",
    "from sklearn.svm import SVC as SVC, LinearSVC as LS\n",
    "\n",
    "mod = LG().fit(t_pre,y)\n",
    "accuracy = cr(mod, t_pre, y, scoring='accuracy', cv=5)\n",
    "f1_score = cr(mod, t_pre, y, scoring='f1', cv=5)\n",
    "print(accuracy.max(), f1_score.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8572891072891073 0.6645813282001924\n"
     ]
    }
   ],
   "source": [
    "mod_1 = LS().fit(t_pre,y)\n",
    "accuracy = cr(mod_1, t_pre, y, scoring='accuracy', cv=5)\n",
    "f1_score = cr(mod_1, t_pre, y, scoring='f1', cv=5)\n",
    "print(accuracy.max(), f1_score.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "16. Посчитайте cross_val_score, если просто удалить значения '?'. Напишите как изменился результат"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "Nan = X.replace(['?'], np.NaN)\n",
    "num_trans = Pipeline(steps=[\n",
    "    ('MS', MinMaxScaler())])\n",
    "cat_trans = Pipeline(steps=[\n",
    "    ('OE', OneHotEncoder())])\n",
    "pre = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', num_trans, num),\n",
    "        ('cat', cat_trans, cat)\n",
    "        ])\n",
    "t_pre_Nan = pre.fit_transform(Nan)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8572891072891073 0.6674618320610687\n"
     ]
    }
   ],
   "source": [
    "mod = LG().fit(t_pre_Nan,y)\n",
    "accuracy = cr(mod, t_pre_Nan, y, scoring='accuracy', cv=5)\n",
    "f1_score = cr(mod, t_pre_Nan, y, scoring='f1', cv=5)\n",
    "print(accuracy.max(), f1_score.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8572891072891073 0.6645813282001924\n"
     ]
    }
   ],
   "source": [
    "mod_1 = LS().fit(t_pre_Nan,y)\n",
    "accuracy = cr(mod_1, t_pre_Nan, y, scoring='accuracy', cv=5)\n",
    "f1_score = cr(mod_1, t_pre_Nan, y, scoring='f1', cv=5)\n",
    "print(accuracy.max(), f1_score.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат улучшился"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17.Посчитайте cross_val_score для RandomForestClassifier,GradientBoostingClassifier. Напишите как изменился результат и какой вывод можно из этого сделать."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8578009828009828 0.6767161410018552\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier as RC, GradientBoostingClassifier as GC\n",
    "mod = RC().fit(t_pre_Nan, y)\n",
    "accuracy = cr(mod, t_pre_Nan, y, scoring='accuracy', cv=5)\n",
    "f1_score = cr(mod, t_pre_Nan, y, scoring='f1', cv=5)\n",
    "print(accuracy.max(), f1_score.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8549344799344799 0.6720704029643354\n"
     ]
    }
   ],
   "source": [
    "mod_1 = GC().fit(t_pre_Nan, y)\n",
    "accuracy = cr(mod, t_pre_Nan, y, scoring='accuracy', cv=5)\n",
    "f1_score = cr(mod, t_pre_Nan, y, scoring='f1', cv=5)\n",
    "print(accuracy.max(), f1_score.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "По результату модель GradientBoostingClassifier самая лучшая."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
